# This workflow will install Python dependencies, run tests and lint with a variety of Python versions
# For more information see: https://help.github.com/actions/language-and-framework-guides/using-python-with-github-actions

name: Python package

on:
  push:
    branches: [ master ]

jobs:
  build-and-test-cuda101:
    name: Tests Cuda 10.1, Python =
    runs-on: GPU4
    strategy:
      matrix:
        python-version: ['3.6', '3.8']
    steps:
    - uses: actions/checkout@v2
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v2
      with:
        python-version: ${{ matrix.python-version }}
    - name: Current dir
      run: pwd
    - run: nvidia-smi
    - name: Create new python env (on self-hosted runners we have to handle isolation ourselves)
      run: |
        python -m venv .env
        source .env/bin/activate
    - name: Set CUDA related environment variables
      run: |
        # We need to export correct pointers for CUDA_HOME and nvcc that corresond to the correct CUDA version.
        source .env/bin/activate
        echo "CUDA_HOME=/usr/local/cuda-10.1/" >> $GITHUB_ENV
        echo "PATH=/usr/local/cuda-10.1/bin:$PATH" >> $GITHUB_ENV  # instead of alias nvcc="/usr/local/cuda-10.1/bin/nvcc"
        echo "LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-10.1/targets/x86_64-linux/lib" >> $GITHUB_ENV
        echo "LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-10.1/extras/CUPTI/lib64" >> $GITHUB_ENV
    - name: Install dependencies
      run: |
        source .env/bin/activate
        pip install --upgrade pip
        pip install -r .github/workflows/dev-requirements.txt
        pip install mxnet-cu101 torch==1.7.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html
        pip install tensorflow
    - name: Check Python and CUDA versions
      run: |
        source .env/bin/activate
        python --version
        python -c "import sys; print('Python version:', sys.version)"
        python -c "import torch; print('Cuda available:', torch.cuda.is_available())"
        python -c "import torch; print('CUDA version used by PyTorch:', torch.version.cuda)"
        python -c "import tensorflow as tf; print('tf: GPUs', tf.config.experimental.list_physical_devices('GPU'))"
        python -c "import tensorflow as tf; print('CUDA version used by Tensorflow:', tf.sysconfig.get_build_info()['cuda_version'])"
        nvcc --version
        echo CUDA_HOME: $CUDA_HOME
    - name: Install package
      run: |
        source .env/bin/activate
        python setup.py develop
    - name: Test
      run: |
        source .env/bin/activate
        python -m pytest

  build-and-test-cuda102:
    name: Tests Cuda 10.2, Python =
    runs-on: GPU4
    strategy:
      matrix:
        python-version: ['3.6', '3.8']
    steps:
      - uses: actions/checkout@v2
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v2
        with:
          python-version: ${{ matrix.python-version }}
      - name: Current dir
        run: pwd
      - run: nvidia-smi
      - name: Create new python env (on self-hosted runners we have to handle isolation ourselves)
        run: |
          python -m venv .env
          source .env/bin/activate
      - name: Set CUDA related environment variables
        run: |
          # We need to export correct pointers for CUDA_HOME and nvcc that corresond to the correct CUDA version.
          source .env/bin/activate
          echo "CUDA_HOME=/usr/local/cuda-10.2/" >> $GITHUB_ENV
          echo "PATH=/usr/local/cuda-10.2/bin:$PATH" >> $GITHUB_ENV  # instead of alias nvcc="/usr/local/cuda-10.2/bin/nvcc"
          echo "LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-10.2/targets/x86_64-linux/lib" >> $GITHUB_ENV
          echo "LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-10.2/extras/CUPTI/lib64" >> $GITHUB_ENV
      - name: Install dependencies
        run: |
          source .env/bin/activate
          pip install --upgrade pip
          pip install -r .github/workflows/dev-requirements.txt
          pip install mxnet-cu102 torch==1.7.1
          pip install tensorflow-gpu # $(python .github/workflows/get_tensorflow_wheel.py | tail -1)
      - name: Check Python and CUDA versions
        run: |
          source .env/bin/activate
          python --version
          python -c "import sys; print('Python version:', sys.version)"
          python -c "import torch; print('Cuda available:', torch.cuda.is_available())"
          python -c "import torch; print('CUDA version used by PyTorch:', torch.version.cuda)"
          python -c "import tensorflow as tf; print('tf: GPUs', tf.config.experimental.list_physical_devices('GPU'))"
          python -c "import tensorflow as tf; print('CUDA version used by Tensorflow:', tf.sysconfig.get_build_info()['cuda_version'])"
          nvcc --version
          echo CUDA_HOME: $CUDA_HOME
      - name: Install package
        run: |
          source .env/bin/activate
          python setup.py develop
      - name: Test
        run: |
          source .env/bin/activate
          python -m pytest

  lint:
    name: Lint with Pylint
    runs-on: self-hosted
    steps:
      - uses: actions/checkout@v2
      - name: Lint with flake8
        run: |
#        # stop the build if there are Python syntax errors or undefined names
          flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
#        # exit-zero treats all errors as warnings. The GitHub editor is 127 chars wide
          flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics